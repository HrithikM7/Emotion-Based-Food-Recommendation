# -*- coding: utf-8 -*-
"""Testing_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iIIatdSZsQhDQqCQTTNV92iYDq0YiSS0
"""

#Emotion-Dataset.zip

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow import keras
from tensorflow.python.keras import layers
from keras.optimizers import Adam
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Dense,Dropout,Flatten
from keras.layers import Conv2D,MaxPooling2D
import shutil
# %matplotlib inline

!unzip /content/drive/MyDrive/Emotion-Dataset.zip

!mkdir actual_train
!mkdir actual_test

import os 
os.mkdir('/content/actual_train/neutral') # train_neutral
os.mkdir('/content/actual_train/positive') # train_positive
os.mkdir('/content/actual_train/negative') # train_negative

os.mkdir('/content/actual_test/neutral') # test_neutral
os.mkdir('/content/actual_test/positive') # test_positive
os.mkdir('/content/actual_test/negative') # test_negative

def moving_files(origin,target):
  
  files = os.listdir(origin)

  for file_name in files : 
    shutil.copy(origin+file_name, target+file_name)

  print("Files are copied successfully")

moving_files('/content/train/angry/','/content/actual_train/negative/')
moving_files('/content/train/disgust/','/content/actual_train/negative/')
moving_files('/content/train/fear/','/content/actual_train/negative/')
moving_files('/content/train/sad/','/content/actual_train/negative/')

moving_files('/content/train/happy/','/content/actual_train/positive/')
moving_files('/content/train/surprise/','/content/actual_train/positive/')

moving_files('/content/train/neutral/','/content/actual_train/neutral/')



moving_files('/content/test/angry/','/content/actual_test/negative/')
moving_files('/content/test/disgust/','/content/actual_test/negative/')
moving_files('/content/test/fear/','/content/actual_test/negative/')
moving_files('/content/test/sad/','/content/actual_test/negative/')

moving_files('/content/test/happy/','/content/actual_test/positive/')
moving_files('/content/test/surprise/','/content/actual_test/positive/')

moving_files('/content/test/neutral/','/content/actual_test/neutral/')

train_gen = ImageDataGenerator(rescale = 1./255,zoom_range = 0.2,shear_range = 0.25,rotation_range = 25,horizontal_flip = True,fill_mode = 'nearest')
train_image = train_gen.flow_from_directory(directory = '/content/actual_train', color_mode = 'grayscale', target_size = (48,48), batch_size = 32,class_mode = "categorical", shuffle = True)

test_gen = ImageDataGenerator(rescale = 1./255)
test_image = test_gen.flow_from_directory(directory = '/content/actual_test', color_mode = 'grayscale', target_size = (48,48), batch_size = 32,class_mode = "categorical", shuffle = True)

train_image.class_indices

class_labels=['Positive','Neutral','Negative']
img, label = train_image.__next__()
print(img,label)

model3 = Sequential()
model3.build(input_shape =(48,48,1))

model3.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))

model3.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
model3.add(MaxPooling2D(pool_size=(2, 2)))
model3.add(Dropout(0.1))

model3.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))
model3.add(MaxPooling2D(pool_size=(2, 2)))
model3.add(Dropout(0.1))

model3.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))
model3.add(MaxPooling2D(pool_size=(2, 2)))
model3.add(Dropout(0.1))

model3.add(Flatten())
model3.add(Dense(512, activation='relu'))
model3.add(Dropout(0.2))

model3.add(Dense(3, activation='softmax'))

model3.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])

epochs=50

history=model3.fit(train_image,
                steps_per_epoch=300,
                epochs=epochs,
                validation_data=test_image,
                validation_steps=100)

model3.save('final_model_file.h5')

import cv2
import numpy as np
from keras.models import load_model

model=load_model('final_model_file.h5')

faceDetect=cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

frame=cv2.imread("/content/20180627194538-GettyImages-828514788.jpeg")
gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
faces= faceDetect.detectMultiScale(gray, 1.3, 3)
for x,y,w,h in faces:
    sub_face_img=gray[y:y+h, x:x+w]
    resized=cv2.resize(sub_face_img,(48,48))
    normalize=resized/255.0jupyter notebook
    reshaped=np.reshape(normalize, (1, 48, 48, 1))
    result=model.predict(reshaped)
    label=np.argmax(result, axis=1)[0]
    print(label)

print(result)

frame=cv2.imread("/content/human-expressions-emotions-young-attractive-man-sad-face-looking-depressed-unhappy-close-up-portrait-handsome-153222267.jpg")
gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
faces= faceDetect.detectMultiScale(gray, 1.3, 3)
for x,y,w,h in faces:
    sub_face_img=gray[y:y+h, x:x+w]
    resized=cv2.resize(sub_face_img,(48,48))
    normalize=resized/255.0
    reshaped=np.reshape(normalize, (1, 48, 48, 1))
    result=model.predict(reshaped)
    label=np.argmax(result, axis=1)[0]
    print(label)

print(result)

frame=cv2.imread("/content/IMG20230128233256.jpg")
gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
faces= faceDetect.detectMultiScale(gray, 1.3, 3)
for x,y,w,h in faces:
    sub_face_img=gray[y:y+h, x:x+w]
    resized=cv2.resize(sub_face_img,(48,48))
    normalize=resized/255.0
    reshaped=np.reshape(normalize, (1, 48, 48, 1))
    result=model.predict(reshaped)
    label=np.argmax(result, axis=1)[0]
    print(label)

print(result)

frame=cv2.imread("/content/download (2).jpg")
gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
faces= faceDetect.detectMultiScale(gray, 1.3, 3)
for x,y,w,h in faces:
    sub_face_img=gray[y:y+h, x:x+w]
    resized=cv2.resize(sub_face_img,(48,48))
    normalize=resized/255.0
    reshaped=np.reshape(normalize, (1, 48, 48, 1))
    result=model.predict(reshaped)
    label=np.argmax(result, axis=1)[0]
    print(label)

print(result)

frame=cv2.imread("/content/happy-smiling-man-looking-away-confident-young-big-smile-handsome-guy-window-thinking-future-closeup-face-152000693.jpg")
gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
faces= faceDetect.detectMultiScale(gray, 1.3, 3)
for x,y,w,h in faces:
    sub_face_img=gray[y:y+h, x:x+w]
    resized=cv2.resize(sub_face_img,(48,48))
    normalize=resized/255.0
    reshaped=np.reshape(normalize, (1, 48, 48, 1))
    result=model.predict(reshaped)
    label=np.argmax(result, axis=1)[0]
    print(label)

print(result)